{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAGgCAYAAAB47/I2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzjUlEQVR4nO3deXRUZZ7/8U9JQgEhKQlIKmGJ6LDJKotAQLaRSFhk7QEce8BBxQV+cICmoe2WZcTIKiqi6NgoCIrTKiCueCCADSggIo3IYLNFIdJGSMJigOT5/eGkmiIBc0Mllafq/TrnnmPdep4835sq75dPbi0uY4wRAAAAAFjsumAXAAAAAADXimADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYIMys23bNv3mN79RfHy8KlasKK/Xq8GDB2vr1q2Ofs60adPkcrlKVENaWppcLpfS0tJKNL+4unbtqq5duxZrXNOmTUu1FgBA0V555RW5XC7fFhERofj4eA0dOlQHDhwotXWvpY9di+L2phtvvFF9+vQp/YKAACPYoEw8++yz6tixo7777jvNnj1bn3zyiebOnavvv/9enTp10sKFC4v9s+677z7HYahAq1attHXrVrVq1apE8wEAoWfJkiXaunWrPvnkE40ePVpr1qxRp06ddPLkyVJZ71r6GIAriwh2AQh9f/3rXzVu3Dj16tVL77zzjiIi/vm0Gzp0qAYMGKCxY8fq1ltvVceOHa/4c86ePasqVaqodu3aql27dolqiYmJUfv27Us0FwAQmpo2bao2bdpI+uWqRl5enqZOnapVq1bp3nvvDfh619LHAFwZV2xQ6lJTU+VyufT888/7hRpJioiI0KJFi+RyufTkk0/69hdcpv/iiy80ePBgVatWTTfffLPffZfKzc3VhAkT5PV6VaVKFXXu3Fk7d+7UjTfeqBEjRvjGFfVStBEjRqhq1ar69ttv1atXL1WtWlV16tTRhAkTlJub67fO9OnT1a5dO8XGxiomJkatWrXSyy+/LGNMgH5bksvl0ujRo7VkyRI1bNhQlStXVps2bbRt2zYZYzRnzhzVq1dPVatWVffu3fXtt9/6zV+3bp369eun2rVrq1KlSvqXf/kXjRo1Sj/++GOhtVavXq3mzZvL7Xbrpptu0tNPP13k79cYo0WLFqlly5aqXLmyqlWrpsGDB+vgwYMBO24AKC8KQs4PP/zgt3/Hjh266667FBsbq0qVKunWW2/Vm2++6Tfm7NmzmjhxourVq6dKlSopNjZWbdq00euvv+4bc/l59vKXxF26XfrSseKei40xmj17thITE1WpUiW1atVKH3zwQYl/H4cPH5bL5dKcOXM0a9Ys3XjjjapcubK6du2q//3f/9WFCxc0efJkJSQkyOPxaMCAATpx4oTfz1i5cqWSk5MVHx+vypUrq3Hjxpo8ebLOnDlTaL2XXnpJDRo0kNvt1i233KIVK1ZoxIgRuvHGG/3GnT9/Xo8//rgaNWokt9utG264Qffee6/+8Y9/lPhYYTeu2KBU5eXlacOGDWrTps0V/zpVp04dtW7dWuvXr1deXp4qVKjgu2/gwIEaOnSoHnzwwSJPfgXuvfderVy5UpMmTVL37t319ddfa8CAAcrOzi5WnRcuXNBdd92lkSNHasKECdq0aZP+67/+Sx6PR4899phv3OHDhzVq1CjVrVtX0i/vGxozZoy+//57v3HXau3atdq1a5eefPJJuVwu/f73v1fv3r01fPhwHTx4UAsXLlRWVpbGjx+vQYMG6csvv/Q1yb///e/q0KGD7rvvPnk8Hh0+fFjz589Xp06dtGfPHkVGRkqSPvzwQw0cOFCdO3fWypUrdfHiRc2dO7dQI5ekUaNG6ZVXXtH/+3//T7NmzdJPP/2kGTNmKCkpSbt371ZcXFzAjh0Agu3QoUOSpAYNGvj2bdiwQT179lS7du30wgsvyOPx6I033tCQIUN09uxZ3x/Rxo8fr2XLlunxxx/XrbfeqjNnzuhvf/ubMjMzr7he7969C700bevWrRo/fryaNGni21fcc/H06dM1ffp0jRw5UoMHD1Z6erruv/9+5eXlqWHDhiX+vTz33HNq3ry5nnvuOZ06dUoTJkxQ37591a5dO0VGRurPf/6zjhw5ookTJ+q+++7TmjVrfHMPHDigXr16ady4cYqKitI333yjWbNm6fPPP9f69et941588UWNGjVKgwYN0lNPPaWsrCxNnz690B8a8/Pz1a9fP23evFmTJk1SUlKSjhw5oqlTp6pr167asWOHKleuXOJjhaUMUIoyMjKMJDN06NCrjhsyZIiRZH744QdjjDFTp041ksxjjz1WaGzBfQX27t1rJJnf//73fuNef/11I8kMHz7ct2/Dhg1GktmwYYNv3/Dhw40k8+abb/rN79Wrl2nYsOEVa87LyzMXLlwwM2bMMNWrVzf5+fm++7p06WK6dOly1WMuGNekSRO/fZKM1+s1p0+f9u1btWqVkWRatmzpt86CBQuMJPPVV18V+fPz8/PNhQsXzJEjR4wks3r1at99bdu2NXXq1DG5ubm+fTk5OaZ69ep+v9+tW7caSWbevHl+Pzs9Pd1UrlzZTJo06VePEwDKoyVLlhhJZtu2bebChQsmJyfHfPjhh8br9ZrOnTubCxcu+MY2atTI3HrrrX77jDGmT58+Jj4+3uTl5RljjGnatKnp37//Vde9vI9d7ptvvjHVq1c33bp1852ji3suPnnypKlUqZIZMGCA37i//vWvRlKxelNiYqLp3bu37/ahQ4eMJNOiRQvfcRrzzx501113+c0fN26ckWSysrKK/PkFvWnjxo1Gktm9e7cx5pe+6vV6Tbt27fzGHzlyxERGRprExETfvoIe/9Zbb/mN3b59u5FkFi1a9KvHidDDS9FQLpj/eynX5S+BGjRo0K/O3bhxoyTp3/7t3/z2Dx48uNBL367E5XKpb9++fvuaN2+uI0eO+O1bv3697rjjDnk8HlWoUEGRkZF67LHHlJmZWeiy+7Xo1q2boqKifLcbN24sSUpJSfH7HRXsv7TOEydO6MEHH1SdOnUUERGhyMhIJSYmSpL27dsnSTpz5ox27Nih/v37q2LFir65VatWLfR7WLt2rVwul+655x5dvHjRt3m9XrVo0aLUP2EOAEpb+/btFRkZqejoaPXs2VPVqlXT6tWrfT3k22+/1TfffKN///d/lyS/c2GvXr10/Phx7d+/X5J022236YMPPtDkyZOVlpamc+fOOaolIyNDPXv2VHx8vN555x3fObq45+KtW7fq559/9tVaICkpydcLSqpXr1667rp//tOxoAf17t3bb1zB/qNHj/r2HTx4UHfffbe8Xq+vf3bp0kXSP3vT/v37lZGRUaif161bt9B7cNeuXavrr79effv29ft9tGzZUl6vl94UpngpGkpVjRo1VKVKFd9l/Ss5fPiwqlSpotjYWL/98fHxv7pGweX9y18OFRERoerVqxerzipVqqhSpUp++9xut37++Wff7c8//1zJycnq2rWrXnrpJdWuXVsVK1bUqlWrNHPmTMfN62ou/z0UNLYr7S+oMz8/X8nJyTp27Jj+9Kc/qVmzZoqKilJ+fr7at2/vq/HkyZMyxhT5ErLL9/3www9XHCtJN910UwmOEADKj6VLl6px48bKycnRypUrtXjxYg0bNsz3vpSCl+hOnDhREydOLPJnFLyP8ZlnnlHt2rW1cuVKzZo1S5UqVdKdd96pOXPmqH79+letIycnR7169dKFCxf0wQcfyOPx+O4r7rm4oCd6vd5CY4ra50RJe9Pp06d1++23q1KlSnr88cfVoEEDValSRenp6Ro4cKCvN12pnxfsu/TfEj/88INOnTrl98e5SxX1vlKEPoINSlWFChXUrVs3ffjhh/ruu++KfJ/Nd999p507dyolJcXv/TVS4Ss4RSkILz/88INq1arl23/x4sWrvqbZqTfeeEORkZFau3atXwhatWpVwNa4Vn/729+0e/duvfLKKxo+fLhv/+UfMFCtWjW5XK4i30+TkZHhd7tGjRpyuVzavHmz3G53ofFF7QMAmzRu3Nj3gQHdunVTXl6e/vu//1t/+ctfNHjwYNWoUUOSNGXKFA0cOLDIn1Hw3pWoqCjfe1x++OEH39Wbvn376ptvvrliDRcuXNCgQYP097//XZs3by7UL4t7Li7oiZefywv2Xf4G/LKwfv16HTt2TGlpab6rNJJ06tQpv3GX9vPLFdWbqlevrg8//LDINaOjo6+xatiIl6Kh1E2ZMkXGGD388MPKy8vzuy8vL08PPfSQjDGaMmVKiX5+586dJf3yiSuX+stf/qKLFy+WrOgiFHx526Xh69y5c1q2bFnA1rhWBUHw8qa3ePFiv9tRUVFq06aNVq1apfPnz/v2nz59WmvXrvUb26dPHxlj9P3336tNmzaFtmbNmpXS0QBAcMyePVvVqlXTY489pvz8fDVs2FD169fX7t27izwPtmnTpsh/SMfFxWnEiBEaNmyY9u/fr7Nnz15xzZEjRyotLU1vv/22mjdvXuj+4p6L27dvr0qVKmn58uV+87ds2VLo5dVlpbi9qWHDhvJ6vYU+ae7o0aPasmWL374+ffooMzNTeXl5Rf4+ruVDEmAvrtig1HXs2FELFizQuHHj1KlTJ40ePVp169bV0aNH9dxzz+mzzz7TggULlJSUVKKf36RJEw0bNkzz5s1ThQoV1L17d+3du1fz5s2Tx+Pxez3wtejdu7fmz5+vu+++Ww888IAyMzM1d+7ccnXFolGjRrr55ps1efJkGWMUGxurd999V+vWrSs0dsaMGerdu7fuvPNOjR07Vnl5eZozZ46qVq2qn376yTeuY8eOeuCBB3Tvvfdqx44d6ty5s6KionT8+HF9+umnatasmR566KGyPEwAKFXVqlXTlClTNGnSJK1YsUL33HOPFi9erJSUFN15550aMWKEatWqpZ9++kn79u3TF198of/5n/+RJLVr1059+vRR8+bNVa1aNe3bt0/Lli1Thw4dVKVKlSLXmzNnjpYtW6YxY8YoKipK27Zt890XExOjW265pdjn4mrVqmnixIl6/PHHdd999+k3v/mN0tPTNW3atGt+KVpJJSUlqVq1anrwwQc1depURUZGavny5dq9e7ffuOuuu07Tp0/XqFGjNHjwYP3nf/6nTp06penTpys+Pt6vnw8dOlTLly9Xr169NHbsWN12222KjIzUd999pw0bNqhfv34aMGBAWR8qgoxggzIxZswYtW3bVvPmzdOECROUmZmp2NhYderUSZ9++qk6dOhwTT9/yZIlio+P18svv6ynnnpKLVu21JtvvqmePXvq+uuvD8gxdO/eXX/+8581a9Ys9e3bV7Vq1dL999+vmjVrauTIkQFZ41pFRkbq3Xff1dixYzVq1ChFRETojjvu0CeffOL7iOoCPXv21FtvvaXHHntMQ4YMkdfr1cMPP6xjx44Vugq1ePFitW/fXosXL9aiRYuUn5+vhIQEdezYUbfddltZHiIAlIkxY8Zo4cKFmjFjhoYNG6Zu3brp888/18yZMzVu3DidPHlS1atX1y233OL3Zvfu3btrzZo1euqpp3T27FnVqlVL//Ef/6FHH330imvt3btXkvTss8/q2Wef9buvS5cuvjfCF/dcPGPGDEVFRWnRokVatmyZGjVqpBdeeEFz584N4G+o+KpXr6733ntPEyZM0D333KOoqCj169dPK1euVKtWrfzGPvDAA3K5XJo9e7YGDBigG2+8UZMnT9bq1av9PoygQoUKWrNmjZ5++mktW7ZMqampioiIUO3atdWlSxdeTRCmXMYE8JsFgXJky5Yt6tixo5YvX66777472OVY4cKFC2rZsqVq1aqljz/+ONjlAACgU6dOqUGDBurfv79efPHFYJeDcowrNggJ69at09atW9W6dWtVrlxZu3fv1pNPPqn69etf8Y2e+OU13T169FB8fLwyMjL0wgsvaN++fXr66aeDXRoAIAxlZGRo5syZ6tatm6pXr64jR47oqaeeUk5OjsaOHRvs8lDOEWwQEmJiYvTxxx9rwYIFysnJUY0aNZSSkqLU1NRCH+OMf8rJydHEiRP1j3/8Q5GRkWrVqpXef/993XHHHcEuDQAQhtxutw4fPqyHH35YP/30k6pUqaL27dvrhRdeUJMmTYJdHso5XooGAAAAwHp83DMAAAAA6xFsAAAAAFiPYAMAAADAeuXuwwPy8/N17NgxRUdH+76pFgBQNowxysnJUUJCQsC+3DYU0JsAIDic9KVyF2yOHTumOnXqBLsMAAhr6enpql27drDLKDfoTQAQXMXpS+Xuz3HR0dHBLgEAwh7nYn/8PgAguIpzHi61YLNo0SLVq1dPlSpVUuvWrbV58+ZizeMSPwAEXyiei0val6TQ/H0AgE2Kcx4ulWCzcuVKjRs3To8++qh27dql22+/XSkpKTp69GhpLAcAwFXRlwAg9JXKF3S2a9dOrVq10vPPP+/b17hxY/Xv31+pqalXnZudnS2PxxPokgAADmRlZSkmJibYZQTMtfQlid4EAMFWnL4U8Cs258+f186dO5WcnOy3Pzk5WVu2bCk0Pjc3V9nZ2X4bAACB4rQvSfQmALBRwIPNjz/+qLy8PMXFxfntj4uLU0ZGRqHxqamp8ng8vo1PnQEABJLTviTRmwDARqX24QGXv8HHGFPkm36mTJmirKws35aenl5aJQEAwlhx+5JEbwIAGwX8e2xq1KihChUqFPor2IkTJwr9tUyS3G633G53oMsAAECS874k0ZsAwEYBv2JTsWJFtW7dWuvWrfPbv27dOiUlJQV6OQAAroq+BADhIeBXbCRp/Pjx+u1vf6s2bdqoQ4cOevHFF3X06FE9+OCDpbEcAABXRV8CgNBXKsFmyJAhyszM1IwZM3T8+HE1bdpU77//vhITE0tjOQAAroq+BAChr1S+x+Za8F0BABB8ofY9NteK3gQAwRWU77EBAAAAgLJGsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKwXEewCgLJUoUIFx3M8Hk8pVHLtRo8e7Wh8lSpVHK/RsGFDx3MeeeQRR+Pnzp3reI1hw4Y5Gv/zzz87XuPJJ590PGf69OmO5wAAgMDgig0AAAAA6xFsAAAAAFgv4MFm2rRpcrlcfpvX6w30MgAAFBu9CQBCX6m8x6ZJkyb65JNPfLdL8r4GAAACid4EAKGtVIJNREQEfwkDAJQr9CYACG2l8h6bAwcOKCEhQfXq1dPQoUN18ODBK47Nzc1Vdna23wYAQKDRmwAgtAU82LRr105Lly7VRx99pJdeekkZGRlKSkpSZmZmkeNTU1Pl8Xh8W506dQJdEgAgzNGbACD0BTzYpKSkaNCgQWrWrJnuuOMOvffee5KkV199tcjxU6ZMUVZWlm9LT08PdEkAgDBHbwKA0FfqX9AZFRWlZs2a6cCBA0Xe73a75Xa7S7sMAAB86E0AEHpK/XtscnNztW/fPsXHx5f2UgAAFAu9CQBCT8CDzcSJE7Vx40YdOnRIn332mQYPHqzs7GwNHz480EsBAFAs9CYACH0Bfynad999p2HDhunHH3/UDTfcoPbt22vbtm1KTEwM9FIAABQLvQkAQl/Ag80bb7wR6B+JcqBu3bqOxlesWNHxGklJSY7ndOrUydH466+/3vEagwYNcjwnVHz33XeO5zzzzDOOxg8YMMDxGjk5OY7G79692/EaGzdudDwH5Re9CQBCX6m/xwYAAAAAShvBBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsFxHsAlD2WrZs6XjO+vXrHY33eDyO10Dpys/Pdzznj3/8o+M5p0+fdjR++fLljtc4fvy4o/EnT550vMb+/fsdzwEAAMHDFRsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArBcR7AJQ9o4ePep4TmZmpqPxHo/H8Rqh4rPPPnM859SpU47ndOvWzdH48+fPO15j2bJljucAAAAEA1dsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1osIdgEoez/99JPjOb/73e8cje/Tp4/jNXbt2uV4zjPPPON4jlNffvmlo/E9evRwvMaZM2ccz2nSpImj8WPHjnW8BgAgNFSuXNnxnKpVqzqe07JlS0fj9+zZ43iNkSNHOp4zc+ZMx3NgH67YAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGC9iGAXADusWrXK0fj169c7XiMnJ8fxnBYtWjgaP3LkSMdrzJ0719H4M2fOOF6jJPbu3eto/AMPPFBKlQAALtW5c2dH4wcOHOh4jaSkJEfj27Zt63iNksjMzHQ0/tVXX3W8xvXXX+94DsIDV2wAAAAAWI9gAwAAAMB6joPNpk2b1LdvXyUkJMjlchV6iZIxRtOmTVNCQoIqV66srl27On7JDAAAxUVfAgBIJQg2Z86cUYsWLbRw4cIi7589e7bmz5+vhQsXavv27fJ6verRo0eJ3j8BAMCvoS8BAKQSfHhASkqKUlJSirzPGKMFCxbo0Ucf9b0R7tVXX1VcXJxWrFihUaNGXVu1AABchr4EAJAC/B6bQ4cOKSMjQ8nJyb59brdbXbp00ZYtW4qck5ubq+zsbL8NAIBAKElfkuhNAGCjgAabjIwMSVJcXJzf/ri4ON99l0tNTZXH4/FtderUCWRJAIAwVpK+JNGbAMBGpfKpaC6Xy++2MabQvgJTpkxRVlaWb0tPTy+NkgAAYcxJX5LoTQBgo4B+QafX65X0y1/I4uPjfftPnDhR6K9lBdxut9xudyDLAABAUsn6kkRvAgAbBfSKTb169eT1erVu3TrfvvPnz2vjxo2OvyEXAIBrRV8CgPDh+IrN6dOn9e233/puHzp0SF9++aViY2NVt25djRs3Tk888YTq16+v+vXr64knnlCVKlV09913B7RwAAAk+hIA4BeOg82OHTvUrVs33+3x48dLkoYPH65XXnlFkyZN0rlz5/Twww/r5MmTateunT7++GNFR0cHrmoAAP4PfQkAIEkuY4wJdhGXys7OlsfjCXYZsMScOXMcjS/4B48TGzdudDT+jjvucLxGfn6+4zlAacrKylJMTEywyyg36E1womfPno7Gz5o1y/EazZs3dzR+586djtd45513HM9p1KiRo/G//e1vHa+B8FScvlQqn4oGAAAAAGWJYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1nMZY0ywi7hUdna2PB5PsMuAJaKiohyNf/fddx2v0aVLF0fjU1JSHK/x8ccfO54DlKasrCzFxMQEu4xyg96E0lSxYkXHc9asWeNo/GuvveZ4jZLMAUpLcfoSV2wAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsJ7LGGOCXcSlsrOz5fF4gl0GQtTNN9/seM4XX3zhaPypU6ccr7FhwwbHc3bs2OFo/HPPPed4jXJ2ekAZysrKUkxMTLDLKDfoTShvWrVq5Wj8a6+95niNu+++2/GcL7/80vEcoDiK05e4YgMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALCeyxhjgl3EpbKzs+XxeIJdBuAzYMAAR+OXLFnieI3o6GjHc5z6wx/+4HjO0qVLHc85fvy44zkof7KyshQTExPsMsoNehNsN3z4cMdznnnmGcdzFi9e7Gj8H//4R8drnD9/3vEc2K84fYkrNgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYz2WMMcEu4lLZ2dnyeDzBLgMosaZNmzqeM3/+fMdz/vVf/9XxHKcWL17seM7MmTMdjf/+++8dr4HSl5WVpZiYmGCXUW7QmxCOEhISHM9JT093NH7VqlWO1xg0aJDjObBfcfoSV2wAAAAAWI9gAwAAAMB6joPNpk2b1LdvXyUkJMjlchW6hDhixAi5XC6/rX379oGqFwAAP/QlAIBUgmBz5swZtWjRQgsXLrzimJ49e+r48eO+7f3337+mIgEAuBL6EgBAkiKcTkhJSVFKSspVx7jdbnm93hIXBQBAcdGXAABSKb3HJi0tTTVr1lSDBg10//3368SJE1ccm5ubq+zsbL8NAIBActKXJHoTANgo4MEmJSVFy5cv1/r16zVv3jxt375d3bt3V25ubpHjU1NT5fF4fFudOnUCXRIAIIw57UsSvQkAbOT4pWi/ZsiQIb7/btq0qdq0aaPExES99957GjhwYKHxU6ZM0fjx4323s7OzaSAAgIBx2pckehMA2CjgweZy8fHxSkxM1IEDB4q83+12y+12l3YZAABI+vW+JNGbAMBGpf49NpmZmUpPT1d8fHxpLwUAwK+iLwFAaHJ8xeb06dP69ttvfbcPHTqkL7/8UrGxsYqNjdW0adM0aNAgxcfH6/Dhw/rDH/6gGjVqaMCAAQEtHAAAib4EAPiF42CzY8cOdevWzXe74DXIw4cP1/PPP689e/Zo6dKlOnXqlOLj49WtWzetXLlS0dHRgasaAID/Q18CAEiSyxhjgl3EpbKzs+XxeIJdBlCmrr/+esdz+vbt62j8kiVLHK/hcrkcz1m/fr2j8T169HC8BkpfVlaWYmJigl1GuUFvQnlToUIFR+MbN27seI1HH33U8ZyhQ4c6Gv/mm286XuPSDwRB+ChOXyr199gAAAAAQGkj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9VzGGBPsIi6VnZ0tj8cT7DKAkJObm+t4TkREhOM5Fy9edDT+zjvvdLxGWlqa4zlwJisrSzExMcEuo9ygN8GJ665z9nfj+Ph4x2vMnTvX0fihQ4c6XiM7O9vxnKVLlzoaP2bMGMdrIDwVpy9xxQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA60UEuwAg1DRv3tzxnMGDBzue07ZtW0fjIyLK5n/3r7/+2tH4TZs2lVIlAOCvQoUKjufUqVPH8Zw33njD0fh27do5XuP8+fOOxj/99NOO15g0aZLjOU7rAgKJKzYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWC8i2AUAZalhw4aO54wePdrR+IEDBzpew+v1Op5TFvLy8hzPOX78uKPx+fn5jtcAgJIoyTnt8OHDjue0b9/e8RwA144rNgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOtFBLsAoIDX63U8Z9iwYY7Gjx492vEaN954o+M55dGOHTscz5k5c6bjOWvWrHE8BwAA4FpxxQYAAACA9Qg2AAAAAKznKNikpqaqbdu2io6OVs2aNdW/f3/t37/fb4wxRtOmTVNCQoIqV66srl27au/evQEtGgCAAvQmAIDkMNhs3LhRjzzyiLZt26Z169bp4sWLSk5O1pkzZ3xjZs+erfnz52vhwoXavn27vF6vevTooZycnIAXDwAAvQkAIDn88IAPP/zQ7/aSJUtUs2ZN7dy5U507d5YxRgsWLNCjjz6qgQMHSpJeffVVxcXFacWKFRo1alTgKgcAQPQmAMAvruk9NllZWZKk2NhYSdKhQ4eUkZGh5ORk3xi3260uXbpoy5YtRf6M3NxcZWdn+20AAJQUvQkAwlOJg40xRuPHj1enTp3UtGlTSVJGRoYkKS4uzm9sXFyc777LpaamyuPx+LY6deqUtCQAQJijNwFA+CpxsBk9erS++uorvf7664Xuc7lcfreNMYX2FZgyZYqysrJ8W3p6eklLAgCEOXoTAISvEn1B55gxY7RmzRpt2rRJtWvX9u0v+ILFjIwMxcfH+/afOHGi0F/KCrjdbrnd7pKUAQCAD70JAMKboys2xhiNHj1ab7/9ttavX6969er53V+vXj15vV6tW7fOt+/8+fPauHGjkpKSAlMxAACXoDcBACSHV2weeeQRrVixQqtXr1Z0dLTvtckej0eVK1eWy+XSuHHj9MQTT6h+/fqqX7++nnjiCVWpUkV33313qRwAACC80ZsAAJLDYPP8889Lkrp27eq3f8mSJRoxYoQkadKkSTp37pwefvhhnTx5Uu3atdPHH3+s6OjogBQMAMCl6E0AAElyGWNMsIu4VHZ2tjweT7DLwGWu9Dr0K7nlllscr7Fw4ULHcxo1auR4Tnn02WefOZ4zZ84cR+NXr17teI38/HzHcxAasrKyFBMTE+wyyg16EwAEV3H60jV9jw0AAAAAlAcEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwXkSwC8C1i42NdTR+8eLFjtdo2bKlo/E33XST4zXKqy1btjgaP2/ePMdrfPTRR47nnDt3zvEcAACAUMUVGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsFxHsAkJZu3btHM/53e9+53jObbfd5mh8rVq1HK9RXp09e9bR+GeeecbxGk888YSj8WfOnHG8BgAAAK4NV2wAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsF5EsAsIZQMGDCiTOWXh66+/djR+7dq1jte4ePGi4znz5s1zNP7UqVOO1wAAAED5xxUbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9VzGGBPsIi6VnZ0tj8cT7DIAIKxlZWUpJiYm2GWUG/QmAAiu4vQlrtgAAAAAsB7BBgAAAID1HAWb1NRUtW3bVtHR0apZs6b69++v/fv3+40ZMWKEXC6X39a+ffuAFg0AQAF6EwBAchhsNm7cqEceeUTbtm3TunXrdPHiRSUnJ+vMmTN+43r27Knjx4/7tvfffz+gRQMAUIDeBACQpAgngz/88EO/20uWLFHNmjW1c+dOde7c2bff7XbL6/UGpkIAAK6C3gQAkK7xPTZZWVmSpNjYWL/9aWlpqlmzpho0aKD7779fJ06cuOLPyM3NVXZ2tt8GAEBJ0ZsAIDyV+OOejTHq16+fTp48qc2bN/v2r1y5UlWrVlViYqIOHTqkP/3pT7p48aJ27twpt9td6OdMmzZN06dPL/kRAAACztaPe6Y3AUBoKlZfMiX08MMPm8TERJOenn7VcceOHTORkZHmrbfeKvL+n3/+2WRlZfm29PR0I4mNjY2NLYhbVlZWSdtDUNGb2NjY2EJzK05fcvQemwJjxozRmjVrtGnTJtWuXfuqY+Pj45WYmKgDBw4Ueb/b7S7yr2UAADhBbwKA8OYo2BhjNGbMGL3zzjtKS0tTvXr1fnVOZmam0tPTFR8fX+IiAQC4EnoTAEBy+OEBjzzyiF577TWtWLFC0dHRysjIUEZGhs6dOydJOn36tCZOnKitW7fq8OHDSktLU9++fVWjRg0NGDCgVA4AABDe6E0AAEly9B4bXeE1b0uWLDHGGHP27FmTnJxsbrjhBhMZGWnq1q1rhg8fbo4ePVrsNbKysoL+Gj42Nja2cN9seo/NlY6B3sTGxsYWOltx+lKJPxWttGRnZ8vj8QS7DAAIa7Z+KlppoTcBQHAVpy9d0/fYAAAAAEB5QLABAAAAYD2CDQAAAADrEWwAAAAAWI9gAwAAAMB6BBsAAAAA1iPYAAAAALAewQYAAACA9Qg2AAAAAKxHsAEAAABgPYINAAAAAOsRbAAAAABYj2ADAAAAwHoEGwAAAADWI9gAAAAAsB7BBgAAAID1CDYAAAAArEewAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwXrkLNsaYYJcAAGGPc7E/fh8AEFzFOQ+Xu2CTk5MT7BIAIOxxLvbH7wMAgqs452GXKWd/hsrPz9exY8cUHR0tl8vld192drbq1Kmj9PR0xcTEBKnC4ODYw+/Yw/W4JY49mMdujFFOTo4SEhJ03XXl7m9fQXOl3hTsxyuYOHaOnWMPH8E8did9KaKMaiq26667TrVr177qmJiYmLB7QhXg2MPv2MP1uCWOPVjH7vF4grJuefZrvYnnKscebjh2jr0sFbcv8ec4AAAAANYj2AAAAACwnlXBxu12a+rUqXK73cEupcxx7OF37OF63BLHHq7HbqNwfrw4do493HDs5f/Yy92HBwAAAACAU1ZdsQEAAACAohBsAAAAAFiPYAMAAADAegQbAAAAANazJtgsWrRI9erVU6VKldS6dWtt3rw52CWVumnTpsnlcvltXq832GWVik2bNqlv375KSEiQy+XSqlWr/O43xmjatGlKSEhQ5cqV1bVrV+3duzc4xQbYrx37iBEjCj0P2rdvH5xiAyw1NVVt27ZVdHS0atasqf79+2v//v1+Y0LxsS/OcYfy4x5K6E30plA7PxUI194Urn1JCo3eZEWwWblypcaNG6dHH31Uu3bt0u23366UlBQdPXo02KWVuiZNmuj48eO+bc+ePcEuqVScOXNGLVq00MKFC4u8f/bs2Zo/f74WLlyo7du3y+v1qkePHsrJySnjSgPv145dknr27On3PHj//ffLsMLSs3HjRj3yyCPatm2b1q1bp4sXLyo5OVlnzpzxjQnFx744xy2F7uMeKuhN9KZQPD8VCNfeFK59SQqR3mQscNttt5kHH3zQb1+jRo3M5MmTg1RR2Zg6dapp0aJFsMsoc5LMO++847udn59vvF6vefLJJ337fv75Z+PxeMwLL7wQhApLz+XHbowxw4cPN/369QtKPWXtxIkTRpLZuHGjMSZ8HvvLj9uY8HrcbUVvCi/0pnf89oXLOSpc+5Ixdvamcn/F5vz589q5c6eSk5P99icnJ2vLli1BqqrsHDhwQAkJCapXr56GDh2qgwcPBrukMnfo0CFlZGT4PQfcbre6dOkSFs8BSUpLS1PNmjXVoEED3X///Tpx4kSwSyoVWVlZkqTY2FhJ4fPYX37cBcLlcbcRvYneFC7np6sJh3NUuPYlyc7eVO6DzY8//qi8vDzFxcX57Y+Li1NGRkaQqiob7dq109KlS/XRRx/ppZdeUkZGhpKSkpSZmRns0spUweMcjs8BSUpJSdHy5cu1fv16zZs3T9u3b1f37t2Vm5sb7NICyhij8ePHq1OnTmratKmk8HjsizpuKXwed1vRm+hN4XB+uppwOEeFa1+S7O1NEcEuoLhcLpffbWNMoX2hJiUlxfffzZo1U4cOHXTzzTfr1Vdf1fjx44NYWXCE43NAkoYMGeL776ZNm6pNmzZKTEzUe++9p4EDBwaxssAaPXq0vvrqK3366aeF7gvlx/5Kxx0uj7vtQvm5eSX0Jn/h+ByQwuMcFa59SbK3N5X7KzY1atRQhQoVCqXgEydOFErLoS4qKkrNmjXTgQMHgl1KmSr4tB2eA7+Ij49XYmJiSD0PxowZozVr1mjDhg2qXbu2b3+oP/ZXOu6ihOLjbjN60z/Rm3gOSKF3jgrXviTZ3ZvKfbCpWLGiWrdurXXr1vntX7dunZKSkoJUVXDk5uZq3759io+PD3YpZapevXryer1+z4Hz589r48aNYfcckKTMzEylp6eHxPPAGKPRo0fr7bff1vr161WvXj2/+0P1sf+14y5KKD3uoYDe9E/0ptA6P5VUqJyjwrUvSSHSm4LxiQVOvfHGGyYyMtK8/PLL5uuvvzbjxo0zUVFR5vDhw8EurVRNmDDBpKWlmYMHD5pt27aZPn36mOjo6JA87pycHLNr1y6za9cuI8nMnz/f7Nq1yxw5csQYY8yTTz5pPB6Pefvtt82ePXvMsGHDTHx8vMnOzg5y5dfuaseek5NjJkyYYLZs2WIOHTpkNmzYYDp06GBq1aoVEsf+0EMPGY/HY9LS0szx48d929mzZ31jQvGx/7XjDvXHPVTQm+hNoXh+KhCuvSlc+5IxodGbrAg2xhjz3HPPmcTERFOxYkXTqlUrv4+eC1VDhgwx8fHxJjIy0iQkJJiBAweavXv3BrusUrFhwwYjqdA2fPhwY8wvH684depU4/V6jdvtNp07dzZ79uwJbtEBcrVjP3v2rElOTjY33HCDiYyMNHXr1jXDhw83R48eDXbZAVHUcUsyS5Ys8Y0Jxcf+14471B/3UEJvojeF2vmpQLj2pnDtS8aERm9yGWNM4K8DAQAAAEDZKffvsQEAAACAX0OwAQAAAGA9gg0AAAAA6xFsAAAAAFiPYAMAAADAegQbAAAAANYj2AAAAACwHsEGAAAAgPUINgAAAACsR7ABAAAAYD2CDQAAAADrEWwAAAAAWO//A6JosdI4mPinAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Function to resize digits within each image\n",
    "def resize_digits(images, scale_factor):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        # Find contours to identify bounding box around digit\n",
    "        contours = measure.find_contours(img, 0.8)\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        ymin, xmin = np.min(contours[0], axis=0)\n",
    "        ymax, xmax = np.max(contours[0], axis=0)\n",
    "\n",
    "        # Extract digit region\n",
    "        digit_region = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "\n",
    "        # Resize digit region\n",
    "        resized_digit = cv2.resize(digit_region, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Create a blank image with the original shape\n",
    "        resized_img = np.zeros_like(img)\n",
    "\n",
    "        # Place the resized digit back into the original image\n",
    "        x_offset = int((img.shape[1] - resized_digit.shape[1]) / 2)\n",
    "        y_offset = int((img.shape[0] - resized_digit.shape[0]) / 2)\n",
    "        resized_img[y_offset:y_offset + resized_digit.shape[0], x_offset:x_offset + resized_digit.shape[1]] = resized_digit\n",
    "\n",
    "        resized_images.append(resized_img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Resize digits within train and test images\n",
    "scale_factor = 0.51 # You can adjust this as needed\n",
    "train_resized = resize_digits(train_images, scale_factor)\n",
    "test_resized = resize_digits(test_images, scale_factor)\n",
    "\n",
    "# Visualize original and resized images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(train_resized[0], cmap='gray')\n",
    "plt.title('Resized Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\d4\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\d4\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\d4\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\d4\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\d4\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "750/750 [==============================] - 11s 13ms/step - loss: 0.2218 - accuracy: 0.9332 - val_loss: 0.0856 - val_accuracy: 0.9750\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.0514 - val_accuracy: 0.9842\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0439 - val_accuracy: 0.9868\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0431 - val_accuracy: 0.9881\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0373 - val_accuracy: 0.9896\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0346 - val_accuracy: 0.9905\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0404 - val_accuracy: 0.9884\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0360 - val_accuracy: 0.9905\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0468 - val_accuracy: 0.9887\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0396 - val_accuracy: 0.9909\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0383 - val_accuracy: 0.9905\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0397 - val_accuracy: 0.9916\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0498 - val_accuracy: 0.9895\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0420 - val_accuracy: 0.9908\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0590 - val_accuracy: 0.9893\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0482 - val_accuracy: 0.9905\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0497 - val_accuracy: 0.9892\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0469 - val_accuracy: 0.9905\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0864 - val_accuracy: 0.9843\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0456 - val_accuracy: 0.9907\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0597 - val_accuracy: 0.9908\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0606 - val_accuracy: 0.9906\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0525 - val_accuracy: 0.9921\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0620 - val_accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0676 - val_accuracy: 0.9911\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0537 - val_accuracy: 0.9918\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0615 - val_accuracy: 0.9899\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0624 - val_accuracy: 0.9910\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0621 - val_accuracy: 0.9896\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0585 - val_accuracy: 0.9909\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 8.5734e-04 - accuracy: 0.9997 - val_loss: 0.0599 - val_accuracy: 0.9909\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0768 - val_accuracy: 0.9877\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0656 - val_accuracy: 0.9908\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9922\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0670 - val_accuracy: 0.9908\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0729 - val_accuracy: 0.9904\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0853 - val_accuracy: 0.9881\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0760 - val_accuracy: 0.9906\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0683 - val_accuracy: 0.9898\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0630 - val_accuracy: 0.9916\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0728 - val_accuracy: 0.9887\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0691 - val_accuracy: 0.9906\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 5.9629e-04 - accuracy: 0.9999 - val_loss: 0.0786 - val_accuracy: 0.9898\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0817 - val_accuracy: 0.9893\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0834 - val_accuracy: 0.9896\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0596 - val_accuracy: 0.9917\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 6.2840e-04 - accuracy: 0.9998 - val_loss: 0.0613 - val_accuracy: 0.9925\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 3.2381e-05 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9922\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 6.9575e-06 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9923\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 4.3215e-06 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9923\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 3.0318e-06 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9923\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 2.1593e-06 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9923\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 1.5238e-06 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9923\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.0658e-06 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9923\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 7.4131e-07 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9923\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 5.1270e-07 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9924\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 3.4740e-07 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9923\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3034e-07 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9926\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 1.5968e-07 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9923\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 1.0573e-07 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9925\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 7.1172e-08 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9926\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 4.8175e-08 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9927\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 3.1913e-08 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9928\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 2.1664e-08 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9927\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 1.4747e-08 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9930\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.0051e-08 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9928\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 6.9092e-09 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9927\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 4.8503e-09 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9927\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 3.4620e-09 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 2.4314e-09 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 1.7434e-09 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9927\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.2790e-09 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9927\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 9.3629e-10 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9927\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 7.2767e-10 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9927\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 5.4389e-10 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9927\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 4.2965e-10 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9927\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 3.2783e-10 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9927\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 2.6325e-10 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9927\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 2.2352e-10 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9927\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.9123e-10 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9927\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.6391e-10 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9927\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.5646e-10 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9927\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.4404e-10 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 1.2666e-10 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9929\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.3659e-10 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9930\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.4404e-10 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.3908e-10 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.3659e-10 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9932\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.1921e-10 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9930\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 1.1673e-10 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 1.2666e-10 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9930\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 1.1673e-10 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 1.2418e-10 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9931\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.1176e-10 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9932\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 1.2169e-10 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9931\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 1.1921e-10 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 1.1176e-10 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 9.4374e-11 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9931\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9938\n",
      "Model trained on original, tested on original MNIST test accuracy: 0.9937999844551086\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the original MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the CNN model\n",
    "model_original = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_original.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_original.fit(train_images, train_labels, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model_original.evaluate(test_images, test_labels)\n",
    "print('Model trained on original, tested on original MNIST test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3244 - accuracy: 0.8996 - val_loss: 0.1166 - val_accuracy: 0.9647\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.1018 - accuracy: 0.9691 - val_loss: 0.0860 - val_accuracy: 0.9732\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0783 - accuracy: 0.9754 - val_loss: 0.0853 - val_accuracy: 0.9743\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.0663 - val_accuracy: 0.9793\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0527 - accuracy: 0.9835 - val_loss: 0.0693 - val_accuracy: 0.9785\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0765 - val_accuracy: 0.9787\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 0.0752 - val_accuracy: 0.9774\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0371 - accuracy: 0.9873 - val_loss: 0.0658 - val_accuracy: 0.9812\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.0651 - val_accuracy: 0.9821\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.0620 - val_accuracy: 0.9818\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.0636 - val_accuracy: 0.9822\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.0671 - val_accuracy: 0.9823\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 0.0718 - val_accuracy: 0.9816\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.0726 - val_accuracy: 0.9817\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0827 - val_accuracy: 0.9811\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.0834 - val_accuracy: 0.9797\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.0831 - val_accuracy: 0.9808\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.0798 - val_accuracy: 0.9827\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0805 - val_accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0773 - val_accuracy: 0.9832\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.0807 - val_accuracy: 0.9828\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0925 - val_accuracy: 0.9829\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.0914 - val_accuracy: 0.9828\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.0801 - val_accuracy: 0.9830\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0819 - val_accuracy: 0.9833\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.0782 - val_accuracy: 0.9843\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0989 - val_accuracy: 0.9826\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0976 - val_accuracy: 0.9831\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0783 - val_accuracy: 0.9844\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0970 - val_accuracy: 0.9810\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0911 - val_accuracy: 0.9840\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.1134 - val_accuracy: 0.9802\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.1055 - val_accuracy: 0.9819\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0902 - val_accuracy: 0.9828\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0998 - val_accuracy: 0.9838\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.1021 - val_accuracy: 0.9813\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0938 - val_accuracy: 0.9828\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.1062 - val_accuracy: 0.9825\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.1047 - val_accuracy: 0.9835\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.1095 - val_accuracy: 0.9832\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.1023 - val_accuracy: 0.9840\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1144 - val_accuracy: 0.9836\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.1224 - val_accuracy: 0.9827\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1053 - val_accuracy: 0.9831\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.1242 - val_accuracy: 0.9819\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1246 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.1276 - val_accuracy: 0.9797\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.1404 - val_accuracy: 0.9793\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1108 - val_accuracy: 0.9830\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.1490 - val_accuracy: 0.9795\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.1465 - val_accuracy: 0.9793\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.1294 - val_accuracy: 0.9810\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.1246 - val_accuracy: 0.9821\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.1279 - val_accuracy: 0.9836\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.1289 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.1205 - val_accuracy: 0.9827\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.1200 - val_accuracy: 0.9830\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.1425 - val_accuracy: 0.9812\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1262 - val_accuracy: 0.9841\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.1517 - val_accuracy: 0.9823\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.1351 - val_accuracy: 0.9830\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.1247 - val_accuracy: 0.9838\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.1538 - val_accuracy: 0.9820\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.1276 - val_accuracy: 0.9832\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1580 - val_accuracy: 0.9788\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.1368 - val_accuracy: 0.9833\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1330 - val_accuracy: 0.9826\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.1408 - val_accuracy: 0.9833\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.1247 - val_accuracy: 0.9827\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1334 - val_accuracy: 0.9841\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.1350 - val_accuracy: 0.9844\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1433 - val_accuracy: 0.9820\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1484 - val_accuracy: 0.9803\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.1397 - val_accuracy: 0.9832\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.1357 - val_accuracy: 0.9835\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1447 - val_accuracy: 0.9812\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.1547 - val_accuracy: 0.9824\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.1697 - val_accuracy: 0.9814\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.1645 - val_accuracy: 0.9809\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.1661 - val_accuracy: 0.9818\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.1504 - val_accuracy: 0.9837\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1448 - val_accuracy: 0.9833\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.1437 - val_accuracy: 0.9831\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.1675 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.1543 - val_accuracy: 0.9806\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.1382 - val_accuracy: 0.9833\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.1427 - val_accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1501 - val_accuracy: 0.9834\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.1557 - val_accuracy: 0.9825\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.1391 - val_accuracy: 0.9841\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1492 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1459 - val_accuracy: 0.9835\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1491 - val_accuracy: 0.9833\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.1438 - val_accuracy: 0.9841\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1441 - val_accuracy: 0.9839\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.1554 - val_accuracy: 0.9823\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.1758 - val_accuracy: 0.9831\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.1703 - val_accuracy: 0.9831\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.1966 - val_accuracy: 0.9814\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 0.9836\n",
      "Model trained on modified, tested on modified MNIST test accuracy 0.9836000204086304\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the resized data\n",
    "train_resized = train_resized.reshape((train_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "test_resized = test_resized.reshape((test_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Build the CNN model for resized MNIST dataset\n",
    "model_resized = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_resized.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_resized.fit(train_resized, train_labels, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_resized, test_acc_resized = model_resized.evaluate(test_resized, test_labels)\n",
    "print('Model trained on modified, tested on modified MNIST test accuracy', test_acc_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 4.4927 - accuracy: 0.5818\n",
      "Model trained on original, tested on modified MNIST test accuracy: 0.5817999839782715\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model trained on standard MNIST dataset on resized MNIST dataset\n",
    "test_loss_original_resized, test_acc_original_resized = model_original.evaluate(test_resized, test_labels)\n",
    "print('Model trained on original, tested on modified MNIST test accuracy:', test_acc_original_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.4478 - accuracy: 0.1011\n",
      "Model trained on modified, tested on original MNIST test accuracy: 0.10109999775886536\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import cv2\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Function to resize digits within each image\n",
    "def resize_digits(images, scale_factor):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        # Find contours to identify bounding box around digit\n",
    "        contours = measure.find_contours(img, 0.8)\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        ymin, xmin = np.min(contours[0], axis=0)\n",
    "        ymax, xmax = np.max(contours[0], axis=0)\n",
    "\n",
    "        # Extract digit region\n",
    "        digit_region = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "\n",
    "        # Resize digit region\n",
    "        if scale_factor > 0:  # Ensure scale factor is greater than 0\n",
    "            if scale_factor >= 1:\n",
    "                resized_digit = cv2.resize(digit_region, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "            else:\n",
    "                resized_digit = cv2.resize(digit_region, (max(1, int(digit_region.shape[1] * scale_factor)), max(1, int(digit_region.shape[0] * scale_factor))), interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            resized_digit = digit_region.copy()  # If scale factor is 0 or negative, keep the original size\n",
    "        \n",
    "        # Create a blank image with the original shape\n",
    "        resized_img = np.zeros_like(img)\n",
    "\n",
    "        # Place the resized digit back into the original image\n",
    "        x_offset = int((img.shape[1] - resized_digit.shape[1]) / 2)\n",
    "        y_offset = int((img.shape[0] - resized_digit.shape[0]) / 2)\n",
    "        resized_img[y_offset:y_offset + resized_digit.shape[0], x_offset:x_offset + resized_digit.shape[1]] = resized_digit\n",
    "\n",
    "        resized_images.append(resized_img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Function to preprocess and reshape MNIST data\n",
    "def preprocess_mnist(images, labels):\n",
    "    images = images.reshape((images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "    labels = to_categorical(labels)\n",
    "    return images, labels\n",
    "\n",
    "# Preprocess the original MNIST dataset\n",
    "train_images, train_labels = preprocess_mnist(train_images, train_labels)\n",
    "test_images, test_labels = preprocess_mnist(test_images, test_labels)\n",
    "\n",
    "# Load the model trained on the resized MNIST dataset\n",
    "# Assuming model_resized is already trained\n",
    "\n",
    "# Resize the original MNIST test images to match the size used during training of the resized model\n",
    "scale_factor = 0.51  # Assuming the same scale factor used during training of the resized model\n",
    "test_images_resized = resize_digits(test_images[:, :, :, 0], scale_factor)\n",
    "\n",
    "# Preprocess the resized test images\n",
    "test_images_resized = test_images_resized.reshape((test_images_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Load the model trained on the resized MNIST dataset\n",
    "# Assuming model_resized is already trained\n",
    "\n",
    "# Evaluate the model trained on resized MNIST dataset on standard MNIST dataset\n",
    "test_loss_resized_original, test_acc_resized_original = model_resized.evaluate(test_images_resized, test_labels)\n",
    "print('Model trained on modified, tested on original MNIST test accuracy:', test_acc_resized_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 13s 14ms/step - loss: 0.2032 - accuracy: 0.9386 - val_loss: 0.0759 - val_accuracy: 0.9779\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0586 - accuracy: 0.9818 - val_loss: 0.0539 - val_accuracy: 0.9835\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 0.0402 - val_accuracy: 0.9887\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.0550 - val_accuracy: 0.9857\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0413 - val_accuracy: 0.9893\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0463 - val_accuracy: 0.9883\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0513 - val_accuracy: 0.9863\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0420 - val_accuracy: 0.9898\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0484 - val_accuracy: 0.9882\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0486 - val_accuracy: 0.9881\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0403 - val_accuracy: 0.9907\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0583 - val_accuracy: 0.9884\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0441 - val_accuracy: 0.9909\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0456 - val_accuracy: 0.9893\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0419 - val_accuracy: 0.9893\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0528 - val_accuracy: 0.9889\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0447 - val_accuracy: 0.9918\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0447 - val_accuracy: 0.9908\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0450 - val_accuracy: 0.9923\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0624 - val_accuracy: 0.9886\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0484 - val_accuracy: 0.9908\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0537 - val_accuracy: 0.9902\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0552 - val_accuracy: 0.9912\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0544 - val_accuracy: 0.9911\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0557 - val_accuracy: 0.9898\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0528 - val_accuracy: 0.9915\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0575 - val_accuracy: 0.9905\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0576 - val_accuracy: 0.9907\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0647 - val_accuracy: 0.9906\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0522 - val_accuracy: 0.9909\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0722 - val_accuracy: 0.9899\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0615 - val_accuracy: 0.9907\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0664 - val_accuracy: 0.9886\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0761 - val_accuracy: 0.9898\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0551 - val_accuracy: 0.9915\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0565 - val_accuracy: 0.9904\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 5.7090e-04 - accuracy: 0.9998 - val_loss: 0.0606 - val_accuracy: 0.9914\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0820 - val_accuracy: 0.9872\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0575 - val_accuracy: 0.9918\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0552 - val_accuracy: 0.9919\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0570 - val_accuracy: 0.9907\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0618 - val_accuracy: 0.9918\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0730 - val_accuracy: 0.9912\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0686 - val_accuracy: 0.9904\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0645 - val_accuracy: 0.9920\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 5.6461e-04 - accuracy: 0.9998 - val_loss: 0.0643 - val_accuracy: 0.9926\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0632 - val_accuracy: 0.9910\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0641 - val_accuracy: 0.9920\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0589 - val_accuracy: 0.9926\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 8.3219e-04 - accuracy: 0.9998 - val_loss: 0.0719 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0667 - val_accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0662 - val_accuracy: 0.9922\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0637 - val_accuracy: 0.9922\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0705 - val_accuracy: 0.9920\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0801 - val_accuracy: 0.9912\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0874 - val_accuracy: 0.9903\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0823 - val_accuracy: 0.9899\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 3.8052e-04 - accuracy: 0.9998 - val_loss: 0.0751 - val_accuracy: 0.9909\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0879 - val_accuracy: 0.9905\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0710 - val_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1068 - val_accuracy: 0.9892\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0776 - val_accuracy: 0.9921\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0888 - val_accuracy: 0.9915\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1085 - val_accuracy: 0.9898\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0938 - val_accuracy: 0.9900\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0871 - val_accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0785 - val_accuracy: 0.9910\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0820 - val_accuracy: 0.9905\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 7.9326e-04 - accuracy: 0.9998 - val_loss: 0.0866 - val_accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 4.2582e-04 - accuracy: 0.9999 - val_loss: 0.0831 - val_accuracy: 0.9920\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 7.0915e-06 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9923\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3687e-06 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9923\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.3671e-06 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9924\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 9.8214e-07 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 7.2805e-07 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9926\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 5.2936e-07 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9926\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 3.8654e-07 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9926\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.8205e-07 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9927\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.0072e-07 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9927\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.4198e-07 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9927\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 9.8775e-08 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9927\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 6.8743e-08 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9927\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 4.7909e-08 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9927\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 3.2926e-08 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9926\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 2.2702e-08 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9925\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.5765e-08 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9924\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.0841e-08 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9925\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 7.5325e-09 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9926\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 5.2825e-09 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9926\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 3.7278e-09 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9927\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 2.6450e-09 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9927\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 1.9073e-09 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9926\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.3933e-09 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9926\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.0133e-09 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9927\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 7.6244e-10 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9927\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 5.8363e-10 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9926\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 4.5200e-10 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9926\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 3.2286e-10 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9926\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3097e-10 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9926\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9935\n",
      "Model trained on original, tested on original MNIST test accuracy: 0.9934999942779541\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 2.3014 - accuracy: 0.1137 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3011 - accuracy: 0.1135\n",
      "Model trained on modified, tested on modified MNIST test accuracy 0.11349999904632568\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.8931 - accuracy: 0.1135\n",
      "Model trained on original, tested on modified MNIST test accuracy: 0.11349999904632568\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3011 - accuracy: 0.1135\n",
      "Model trained on modified, tested on original MNIST test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import cv2\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load the original MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the CNN model\n",
    "model_original = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_original.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_original.fit(train_images, train_labels, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model_original.evaluate(test_images, test_labels)\n",
    "print('Model trained on original, tested on original MNIST test accuracy:', test_acc)\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the resized data\n",
    "train_resized = train_resized.reshape((train_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "test_resized = test_resized.reshape((test_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Build the CNN model for resized MNIST dataset\n",
    "model_resized = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_resized.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_resized.fit(train_resized, train_labels, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_resized, test_acc_resized = model_resized.evaluate(test_resized, test_labels)\n",
    "print('Model trained on modified, tested on modified MNIST test accuracy', test_acc_resized)\n",
    "\n",
    "\n",
    "# Evaluate the model trained on standard MNIST dataset on resized MNIST dataset\n",
    "test_loss_original_resized, test_acc_original_resized = model_original.evaluate(test_resized, test_labels)\n",
    "print('Model trained on original, tested on modified MNIST test accuracy:', test_acc_original_resized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to resize digits within each image\n",
    "def resize_digits(images, scale_factor):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        # Find contours to identify bounding box around digit\n",
    "        contours = measure.find_contours(img, 0.8)\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        ymin, xmin = np.min(contours[0], axis=0)\n",
    "        ymax, xmax = np.max(contours[0], axis=0)\n",
    "\n",
    "        # Extract digit region\n",
    "        digit_region = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "\n",
    "        # Resize digit region\n",
    "        if scale_factor > 0:  # Ensure scale factor is greater than 0\n",
    "            if scale_factor >= 1:\n",
    "                resized_digit = cv2.resize(digit_region, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "            else:\n",
    "                resized_digit = cv2.resize(digit_region, (max(1, int(digit_region.shape[1] * scale_factor)), max(1, int(digit_region.shape[0] * scale_factor))), interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            resized_digit = digit_region.copy()  # If scale factor is 0 or negative, keep the original size\n",
    "        \n",
    "        # Create a blank image with the original shape\n",
    "        resized_img = np.zeros_like(img)\n",
    "\n",
    "        # Place the resized digit back into the original image\n",
    "        x_offset = int((img.shape[1] - resized_digit.shape[1]) / 2)\n",
    "        y_offset = int((img.shape[0] - resized_digit.shape[0]) / 2)\n",
    "        resized_img[y_offset:y_offset + resized_digit.shape[0], x_offset:x_offset + resized_digit.shape[1]] = resized_digit\n",
    "\n",
    "        resized_images.append(resized_img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Function to preprocess and reshape MNIST data\n",
    "def preprocess_mnist(images, labels):\n",
    "    images = images.reshape((images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "    labels = to_categorical(labels)\n",
    "    return images, labels\n",
    "\n",
    "# Preprocess the original MNIST dataset\n",
    "train_images, train_labels = preprocess_mnist(train_images, train_labels)\n",
    "test_images, test_labels = preprocess_mnist(test_images, test_labels)\n",
    "\n",
    "# Load the model trained on the resized MNIST dataset\n",
    "# Assuming model_resized is already trained\n",
    "\n",
    "# Resize the original MNIST test images to match the size used during training of the resized model\n",
    "scale_factor = 0.51  # Assuming the same scale factor used during training of the resized model\n",
    "test_images_resized = resize_digits(test_images[:, :, :, 0], scale_factor)\n",
    "\n",
    "# Preprocess the resized test images\n",
    "test_images_resized = test_images_resized.reshape((test_images_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Load the model trained on the resized MNIST dataset\n",
    "# Assuming model_resized is already trained\n",
    "\n",
    "# Evaluate the model trained on resized MNIST dataset on standard MNIST dataset\n",
    "test_loss_resized_original, test_acc_resized_original = model_resized.evaluate(test_images_resized, test_labels)\n",
    "print('Model trained on modified, tested on original MNIST test accuracy:', test_acc_resized_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Resize the original MNIST dataset\u001b[39;00m\n\u001b[0;32m     41\u001b[0m scale_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.51\u001b[39m\n\u001b[1;32m---> 42\u001b[0m train_images_resized \u001b[38;5;241m=\u001b[39m resize_digits(train_images[:, :, :, \u001b[38;5;241m0\u001b[39m], scale_factor)\n\u001b[0;32m     43\u001b[0m test_images_resized \u001b[38;5;241m=\u001b[39m resize_digits(test_images[:, :, :, \u001b[38;5;241m0\u001b[39m], scale_factor)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Preprocess the resized data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mresize_digits\u001b[1;34m(images, scale_factor)\u001b[0m\n\u001b[0;32m     28\u001b[0m digit_region \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28mint\u001b[39m(ymin):\u001b[38;5;28mint\u001b[39m(ymax), \u001b[38;5;28mint\u001b[39m(xmin):\u001b[38;5;28mint\u001b[39m(xmax)]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale_factor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m     resized_digit \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(digit_region, \u001b[38;5;28;01mNone\u001b[39;00m, fx\u001b[38;5;241m=\u001b[39mscale_factor, fy\u001b[38;5;241m=\u001b[39mscale_factor, interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     resized_digit \u001b[38;5;241m=\u001b[39m digit_region\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from skimage import measure\n",
    "import cv2\n",
    "\n",
    "# Load the original MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_mnist(images, labels):\n",
    "    images = images.reshape((images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "    labels = to_categorical(labels)\n",
    "    return images, labels\n",
    "\n",
    "train_images, train_labels = preprocess_mnist(train_images, train_labels)\n",
    "test_images, test_labels = preprocess_mnist(test_images, test_labels)\n",
    "\n",
    "# Function to resize digits within each image\n",
    "def resize_digits(images, scale_factor):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        contours = measure.find_contours(img, 0.8)\n",
    "        ymin, xmin = np.min(contours[0], axis=0)\n",
    "        ymax, xmax = np.max(contours[0], axis=0)\n",
    "        digit_region = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "        if scale_factor > 0:\n",
    "            resized_digit = cv2.resize(digit_region, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            resized_digit = digit_region.copy()\n",
    "        resized_img = np.zeros_like(img)\n",
    "        x_offset = int((img.shape[1] - resized_digit.shape[1]) / 2)\n",
    "        y_offset = int((img.shape[0] - resized_digit.shape[0]) / 2)\n",
    "        resized_img[y_offset:y_offset + resized_digit.shape[0], x_offset:x_offset + resized_digit.shape[1]] = resized_digit\n",
    "        resized_images.append(resized_img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Resize the original MNIST dataset\n",
    "scale_factor = 0.51\n",
    "train_images_resized = resize_digits(train_images[:, :, :, 0], scale_factor)\n",
    "test_images_resized = resize_digits(test_images[:, :, :, 0], scale_factor)\n",
    "\n",
    "# Preprocess the resized data\n",
    "train_images_resized = train_images_resized.reshape((train_images_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "test_images_resized = test_images_resized.reshape((test_images_resized.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Combine original and resized datasets for training\n",
    "combined_train_images = np.concatenate((train_images, train_images_resized), axis=0)\n",
    "combined_train_labels = np.concatenate((train_labels, train_labels), axis=0)\n",
    "\n",
    "# Build the CNN model\n",
    "model_combined = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_combined.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the combined dataset\n",
    "model_combined.fit(combined_train_images, combined_train_labels, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the original test set\n",
    "test_loss_original, test_acc_original = model_combined.evaluate(test_images, test_labels)\n",
    "print('Model trained on combined, tested on original MNIST test accuracy:', test_acc_original)\n",
    "\n",
    "# Evaluate the model on the resized test set\n",
    "test_loss_resized, test_acc_resized = model_combined.evaluate(test_images_resized, test_labels)\n",
    "print('Model trained on combined, tested on resized MNIST test accuracy:', test_acc_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
